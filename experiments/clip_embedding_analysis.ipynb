{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf3Cy65j8WWS"
      },
      "source": [
        "# Prerequisite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZYGq-1q0rLb",
        "outputId": "27ae5681-33e3-405c-ad64-b74e2c6c19da"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "from torchvision.datasets import ImageNet\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import umap\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 设置新的工作目录 \n",
        "os.chdir('/hpc2hdd/home/erjiaxiao/erjia/LLaVA')\n",
        "print(\"change curr dir to\", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRg5TEA7Mfet"
      },
      "source": [
        "# CLIP Embedding Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1-Sl8DmMm3N",
        "outputId": "31d572bf-d0a3-4655-835a-726ded71ba2e"
      },
      "outputs": [],
      "source": [
        "# 加载 CLIP 模型\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_name = \"openai/clip-vit-large-patch14-336\"\n",
        "model = CLIPModel.from_pretrained(model_name).to(device)\n",
        "processor = CLIPProcessor.from_pretrained(model_name)\n",
        "\n",
        "# 加载 ImageNet 数据集\n",
        "dataset = ImageNet(root='datasets/ImageNet/', split='val', transform=transforms.Compose([transforms.Resize((336, 336))]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 查看一张添加typo的图片与原图和目标图的embedding之间的关系\n",
        "label_image_dict = {}\n",
        "for image, label in tqdm(dataset):\n",
        "    \n",
        "    label = dataset.classes[label][0]\n",
        "    \n",
        "    if label in label_image_dict:\n",
        "        label_image_dict[label].append(image)\n",
        "    else:\n",
        "        label_image_dict[label] = [image]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_text_background(label):\n",
        "    \n",
        "    num_prints = 1\n",
        "    resolution = (336, 336)\n",
        "    bg_color = 'white'\n",
        "    font_color = 'black'\n",
        "    font_size = 15\n",
        "    font_path = 'fonts/arial_bold.ttf'\n",
        "    \n",
        "    image = Image.new('RGB', resolution, bg_color)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    font = ImageFont.truetype(font_path, font_size)\n",
        "\n",
        "    max_x = image.width\n",
        "    max_y = image.height\n",
        "\n",
        "    text_width = int(draw.textlength(label, font=font))\n",
        "    text_height = 30\n",
        "\n",
        "    start_x = (max_x - text_width) // 2\n",
        "    start_y = (max_y - num_prints * text_height) // 2   # 确保多行文本都在图片中心\n",
        "\n",
        "    positions = [(start_x, start_y + i * text_height) for i in range(num_prints)]\n",
        "\n",
        "    for pos in positions:\n",
        "        draw.text(pos, label, fill=font_color, font=font)\n",
        "\n",
        "    return image\n",
        "\n",
        "total_sim = [[] for i in range(8)]\n",
        "\n",
        "image_root = \"images/species-r1/\"\n",
        "for i, img in enumerate(os.listdir(image_root)):\n",
        "\n",
        "    name = img\n",
        "    img_typo = \"images/species-r1/\" + img\n",
        "    img = \"images/species-r0/\" + img\n",
        "    label = img_typo.split('.')[-2].split('-')[-2]\n",
        "    mislabel = img_typo.split('.')[-2].split('-')[-1]\n",
        "        \n",
        "    # 保存 embedding 用于降维分析\n",
        "    embeddings_label = [] \n",
        "    embeddings_mislabel = [] \n",
        "    embedding_img_typo = None\n",
        "    embedding_img = None\n",
        "    embedding_bg_label = None\n",
        "    embedding_bg_mislabel = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            img = Image.open(img)\n",
        "            inputs = processor(text=label, images=img, return_tensors=\"pt\", padding=True).to(device)\n",
        "            embedding_img = model(**inputs).image_embeds\n",
        "            \n",
        "            img_typo = Image.open(img_typo)\n",
        "            inputs = processor(text=label, images=img_typo, return_tensors=\"pt\", padding=True).to(device)\n",
        "            embedding_img_typo = model(**inputs).image_embeds\n",
        "            \n",
        "            bg_label = add_text_background(label)\n",
        "            inputs = processor(text=label, images=bg_label, return_tensors=\"pt\", padding=True).to(device)\n",
        "            embedding_bg_label = model(**inputs).image_embeds\n",
        "            \n",
        "            bg_mislabel = add_text_background(mislabel)\n",
        "            inputs = processor(text=label, images=bg_mislabel, return_tensors=\"pt\", padding=True).to(device)\n",
        "            embedding_bg_mislabel = model(**inputs).image_embeds\n",
        "\n",
        "            for img in label_image_dict[label]:\n",
        "                inputs = processor(text=label, images=img, return_tensors=\"pt\", padding=True).to(device)\n",
        "                embedding = model(**inputs).image_embeds\n",
        "                embeddings_label.append(embedding)\n",
        "                \n",
        "            for img in label_image_dict[mislabel]:\n",
        "                inputs = processor(text=mislabel, images=img, return_tensors=\"pt\", padding=True).to(device)\n",
        "                embedding = model(**inputs).image_embeds\n",
        "                embeddings_mislabel.append(embedding)\n",
        "                \n",
        "            # 计算余弦相似度并存储平均值的函数\n",
        "            def calculate_and_store_similarity(embedding1, embedding2, total_sim_list):\n",
        "                similarities = F.cosine_similarity(embedding1.unsqueeze(0), embedding2)\n",
        "                average_similarity = torch.mean(similarities).item()\n",
        "                # print(average_similarity)\n",
        "                total_sim_list.append(average_similarity)\n",
        "\n",
        "            # 余弦相似度计算的组合列表\n",
        "            embedding_combinations = [\n",
        "                (embedding_img, torch.stack(embeddings_label), total_sim[0]),\n",
        "                (embedding_img, torch.stack(embeddings_mislabel), total_sim[1]),\n",
        "                (embedding_img_typo, torch.stack(embeddings_label), total_sim[2]),\n",
        "                (embedding_img_typo, torch.stack(embeddings_mislabel), total_sim[3]),\n",
        "                (embedding_img, embedding_bg_label.unsqueeze(0), total_sim[4]),\n",
        "                (embedding_img, embedding_bg_mislabel.unsqueeze(0), total_sim[5]),\n",
        "                (embedding_img_typo, embedding_bg_label.unsqueeze(0), total_sim[6]),\n",
        "                (embedding_img_typo, embedding_bg_mislabel.unsqueeze(0), total_sim[7]),\n",
        "            ]\n",
        "\n",
        "            # 计算每一对嵌入的余弦相似度并打印和存储结果\n",
        "            for embedding1, embedding2, total_sim_list in embedding_combinations:\n",
        "                calculate_and_store_similarity(embedding1, embedding2, total_sim_list)\n",
        "\n",
        "            # 设置 Matplotlib 的风格为 'seaborn-colorblind'\n",
        "            plt.style.use('seaborn-colorblind')\n",
        "\n",
        "            numpy_embeddings_label = np.vstack([e.cpu().detach().numpy() for e in embeddings_label])\n",
        "            numpy_embeddings_mislabel = np.vstack([e.cpu().detach().numpy() for e in embeddings_mislabel])\n",
        "            numpy_embedding_img_typo = embedding_img_typo.cpu().detach().numpy().reshape(1, -1)\n",
        "            numpy_embedding_img = embedding_img.cpu().detach().numpy().reshape(1, -1)\n",
        "            numpy_embedding_bg_label = embedding_bg_label.cpu().detach().numpy().reshape(1, -1)\n",
        "            numpy_embedding_bg_mislabel = embedding_bg_mislabel.cpu().detach().numpy().reshape(1, -1)\n",
        "\n",
        "            # 将所有numpy数组堆叠成一个大的数组\n",
        "            numpy_embeddings = np.vstack((\n",
        "                numpy_embeddings_label,\n",
        "                numpy_embeddings_mislabel,\n",
        "                numpy_embedding_img_typo,\n",
        "                numpy_embedding_img,\n",
        "                numpy_embedding_bg_label,\n",
        "                numpy_embedding_bg_mislabel\n",
        "            ))\n",
        "\n",
        "            # 创建一个颜色数组，对应每个embedding的来源\n",
        "            colors = np.concatenate([\n",
        "                ['blue'] * len(embeddings_label),\n",
        "                ['red'] * len(embeddings_mislabel),  \n",
        "                ['green'],  \n",
        "                ['purple'],  \n",
        "                ['orange'],  \n",
        "                ['gray']  \n",
        "            ])\n",
        "\n",
        "            # # 标准化数据\n",
        "            # scaler = StandardScaler()\n",
        "            # data_scaled = scaler.fit_transform(numpy_embeddings)\n",
        "\n",
        "            # # 计算PCA，选择保留前两个主成分\n",
        "            # pca = PCA(n_components=2)\n",
        "            # principal_components = pca.fit_transform(data_scaled)\n",
        "\n",
        "            # # 可视化PCA结果，为不同的embedding设置不同的颜色\n",
        "            # for i, color in enumerate(colors):\n",
        "            #     plt.scatter(principal_components[i, 0], principal_components[i, 1], s=8, c=color)\n",
        "\n",
        "            # plt.xlabel('Principal Component 1')\n",
        "            # plt.ylabel('Principal Component 2')\n",
        "            # plt.title('PCA Visualization of Embeddings')\n",
        "            # plt.grid(True)\n",
        "            # plt.savefig(f\"pca/{name}.png\")\n",
        "            # plt.clf()\n",
        "            # plt.show()\n",
        "\n",
        "            # 使用 TSNE 降维\n",
        "            tsne = TSNE(n_components=2)\n",
        "            tsne_embeddings = tsne.fit_transform(numpy_embeddings)\n",
        "\n",
        "            # 可视化 TSNE 结果，为不同的embedding设置不同的颜色\n",
        "            for i, color in enumerate(colors):\n",
        "                plt.scatter(tsne_embeddings[i, 0], tsne_embeddings[i, 1], s=8, c=color)\n",
        "\n",
        "            plt.xlabel('t-SNE Dimension 1')\n",
        "            plt.ylabel('t-SNE Dimension 2')\n",
        "            plt.title('t-SNE Visualization of Embeddings')\n",
        "            plt.grid(True)\n",
        "            plt.savefig(f\"tsne/{name}.png\")\n",
        "            plt.clf()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            pass\n",
        "        \n",
        "# for sim_list in total_sim:\n",
        "#     print(sum(sim_list) / len(sim_list) if len(sim_list) > 0 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E447saMgSzzp",
        "outputId": "5bfc2756-7eb9-4003-beb6-b06b76d99cff"
      },
      "outputs": [],
      "source": [
        "def add_text_img(image, text, num_prints=1, min_distance=20):\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.load_default()\n",
        "    text_color = \"white\"\n",
        "\n",
        "    text_width, text_height = draw.textsize(text, font=font)\n",
        "\n",
        "    max_x = image.width - text_width\n",
        "    max_y = image.height - text_height\n",
        "\n",
        "    if max_x < 0:\n",
        "        max_x = 0\n",
        "    if max_y < 0:\n",
        "        max_y = 0\n",
        "\n",
        "    positions = []\n",
        "    for _ in range(num_prints):\n",
        "        while True:\n",
        "            text_x = random.randint(0, max_x)\n",
        "            text_y = random.randint(0, max_y)\n",
        "            valid_position = True\n",
        "\n",
        "            for pos in positions:\n",
        "                if abs(text_x - pos[0]) < min_distance and abs(text_y - pos[1]) < min_distance:\n",
        "                    valid_position = False\n",
        "                    break\n",
        "\n",
        "            if valid_position:\n",
        "                positions.append((text_x, text_y))\n",
        "                break\n",
        "\n",
        "        draw.text((text_x, text_y), text, fill=text_color, font=font)\n",
        "\n",
        "    return image\n",
        "\n",
        "def add_text_bg(text):\n",
        "    color_names = [\n",
        "        \"white\", \"yellow\", \"cyan\", \"lightgreen\", \"lightblue\",\n",
        "        \"orange\", \"pink\", \"gold\", \"peach\", \"lime\"\n",
        "    ]\n",
        "    colors = {\n",
        "        \"white\": (255, 255, 255),\n",
        "        \"yellow\": (255, 255, 0),\n",
        "        \"cyan\": (0, 255, 255),\n",
        "        \"lightgreen\": (144, 238, 144),\n",
        "        \"lightblue\": (173, 216, 230),\n",
        "        \"orange\": (255, 165, 0),\n",
        "        \"pink\": (255, 192, 203),\n",
        "        \"gold\": (255, 215, 0),\n",
        "        \"peach\": (255, 218, 185),\n",
        "        \"lime\": (0, 255, 0)\n",
        "    }\n",
        "\n",
        "    selected_color_name = random.choice(color_names)\n",
        "    selected_color = colors[selected_color_name]\n",
        "\n",
        "    image = Image.new(\"RGB\", (224, 224), selected_color)\n",
        "\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.load_default()\n",
        "    text_color = \"black\"\n",
        "\n",
        "    text_width, text_height = draw.textsize(text, font=font)\n",
        "\n",
        "    max_x = 224 - text_width\n",
        "    max_y = 224 - text_height\n",
        "\n",
        "    if max_x < 0:\n",
        "        max_x = 0\n",
        "    if max_y < 0:\n",
        "        max_y = 0\n",
        "\n",
        "    text_x = random.randint(0, max_x)\n",
        "    text_y = random.randint(0, max_y)\n",
        "\n",
        "    draw.text((text_x, text_y), text, fill=text_color, font=font)\n",
        "    return image\n",
        "\n",
        "# 保存 embedding 用于降维分析\n",
        "embeddings = []\n",
        "\n",
        "# 定义阈值，达到这个次数后才继续下一张图片输入，使用字典来跟踪标签出现的次数\n",
        "threshold = 5\n",
        "duplicate = {}\n",
        "num = 50\n",
        "count = 0\n",
        "\n",
        "# 遍历前 num 张图像和标签\n",
        "for k, (image, label) in enumerate(dataset):\n",
        "    if count >= num:\n",
        "        break\n",
        "\n",
        "    # 获取图像的类别名\n",
        "    label = dataset.classes[label][0]\n",
        "\n",
        "    # 检查标签是否在字典中\n",
        "    if label in duplicate:\n",
        "        # 如果标签出现次数未达到阈值，增加计数\n",
        "        if duplicate[label] < threshold:\n",
        "            duplicate[label] += 1\n",
        "        else:\n",
        "            # 如果标签已经达到阈值，继续下一张图片\n",
        "            continue\n",
        "    else:\n",
        "        # 如果标签不在字典中，添加并初始化计数\n",
        "        duplicate[label] = 1\n",
        "\n",
        "    classes = [t[0] for t in dataset.classes]\n",
        "    mislabel1 = random.choice(classes)\n",
        "    mislabel2 = random.choice(classes)\n",
        "\n",
        "    # 处理图像\n",
        "    img_mislabel1 = add_text_img(image.copy(), mislabel1)\n",
        "    bg_mislabel1 = add_text_bg(mislabel1)\n",
        "    bg_mislabel2 = add_text_bg(mislabel2)\n",
        "    bg_label = add_text_bg(label)\n",
        "\n",
        "    # 提取 CLIP embedding\n",
        "    inputs1 = processor(text=[label], images=image,\n",
        "                        return_tensors=\"pt\", padding=True).to(device)\n",
        "    inputs2 = processor(text=[label], images=img_mislabel1,\n",
        "                        return_tensors=\"pt\", padding=True).to(device)\n",
        "    inputs3 = processor(text=[label], images=bg_mislabel1,\n",
        "                        return_tensors=\"pt\", padding=True).to(device)\n",
        "    inputs4 = processor(text=[label], images=bg_mislabel2,\n",
        "                        return_tensors=\"pt\", padding=True).to(device)\n",
        "    inputs5 = processor(text=[label], images=bg_label,\n",
        "                        return_tensors=\"pt\", padding=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        img1_embedding = model(**inputs1).image_embeds\n",
        "        img2_embedding = model(**inputs2).image_embeds\n",
        "        img3_embedding = model(**inputs3).image_embeds\n",
        "        img4_embedding = model(**inputs4).image_embeds\n",
        "        img5_embedding = model(**inputs5).image_embeds\n",
        "        diff21_embedding = img2_embedding - img1_embedding\n",
        "        diff23_embedding = img2_embedding - img3_embedding\n",
        "        diff24_embedding = img2_embedding - img4_embedding\n",
        "        diff25_embedding = img2_embedding - img5_embedding\n",
        "        text_embedding = model(**inputs1).text_embeds[0].unsqueeze(0)\n",
        "\n",
        "    temp_embeddings = [img1_embedding, img2_embedding, img3_embedding, img4_embedding, img5_embedding,\n",
        "                       diff21_embedding, diff23_embedding, diff24_embedding, diff25_embedding, text_embedding]\n",
        "\n",
        "    # 用于降维分析\n",
        "    for emb in temp_embeddings:\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    # 初始化一个矩阵用于存储余弦相似度\n",
        "    # num_embeddings = len(temp_embeddings)\n",
        "    # cosine_similarities = torch.zeros((num_embeddings, num_embeddings))\n",
        "\n",
        "    # 计算余弦相似度\n",
        "    # for i in range(num_embeddings):\n",
        "    #     for j in range(num_embeddings):\n",
        "    #         similarity = F.cosine_similarity(temp_embeddings[i], temp_embeddings[j])\n",
        "    #         cosine_similarities[i, j] = round(similarity.item(), 3)\n",
        "\n",
        "    # 打印余弦相似度矩阵\n",
        "    # print(cosine_similarities)\n",
        "    # print()\n",
        "\n",
        "    # 保存处理后的图像\n",
        "    img_mislabel1.save(str(k) + label + '_img_mislabel1.jpg')\n",
        "    bg_mislabel1.save(str(k) + label + '_bg_mislabel1.jpg')\n",
        "    bg_mislabel2.save(str(k) + label + '_bg_mislabel2.jpg')\n",
        "    bg_label.save(str(k) + label + '_bg_label.jpg')\n",
        "\n",
        "    count += 1\n",
        "    if count % 10 == 0:\n",
        "        print(str(k), \":\", str(count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "eDDDyBEsgvgR",
        "outputId": "5da93eb3-0122-4f83-821d-b71a5fe3e174"
      },
      "outputs": [],
      "source": [
        "# PCA\n",
        "numpy_embeddings = np.empty((0, embeddings[0].shape[1]))\n",
        "for emb in embeddings:\n",
        "    numpy_embeddings = np.vstack(\n",
        "        (numpy_embeddings, emb.cpu().detach().numpy()))\n",
        "\n",
        "# 每组图片的数量\n",
        "group = len(temp_embeddings)\n",
        "\n",
        "# 使用布尔索引去除指定下标\n",
        "# arr = np.arange(len(numpy_embeddings))\n",
        "# temp = [arr % group == 9]\n",
        "# indices_to_keep = np.logical_not(np.logical_or.reduce(temp))\n",
        "# numpy_embeddings = numpy_embeddings[indices_to_keep]\n",
        "# group -= len(temp)\n",
        "\n",
        "# 标准化数据\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(numpy_embeddings)\n",
        "\n",
        "# 计算PCA，选择保留前两个主成分\n",
        "pca = PCA(n_components=2)\n",
        "principal_components = pca.fit_transform(data_scaled)\n",
        "\n",
        "# 只显示前k组数据\n",
        "# principal_components = principal_components[:group*2]\n",
        "\n",
        "# 根据下标为每个数据点分配不同的颜色\n",
        "colors = ['magenta', 'blue', 'green', 'purple', 'orange', 'pink', 'brown',\n",
        "          'gray', 'cyan', 'red', 'teal', 'lime', 'indigo', 'maroon', 'olive']\n",
        "colors_for_points = [colors[i % group]\n",
        "                     for i in range(len(principal_components))]\n",
        "\n",
        "# 可视化PCA结果\n",
        "plt.scatter(principal_components[:, 0],\n",
        "            principal_components[:, 1], c=colors_for_points, s=8)\n",
        "\n",
        "# 使用循环标记每个点的序号\n",
        "for i, (x, y) in enumerate(zip(principal_components[:, 0], principal_components[:, 1])):\n",
        "    if i < group:\n",
        "        plt.annotate(str(i+1), (x, y), textcoords=\"offset points\",\n",
        "                     xytext=(0, 0), ha='center')\n",
        "\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('PCA Visualization with Labels (Starting from 1)')\n",
        "# plt.savefig(\"pca_visualization.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "OsJMIsoswPQw",
        "outputId": "bc008183-2207-425e-e5d4-006ee9eaa96b"
      },
      "outputs": [],
      "source": [
        "# UMAP\n",
        "numpy_embeddings = np.empty((0, embeddings[0].shape[1]))\n",
        "for emb in embeddings:\n",
        "    numpy_embeddings = np.vstack(\n",
        "        (numpy_embeddings, emb.cpu().detach().numpy()))\n",
        "\n",
        "# 每组图片的数量\n",
        "group = len(temp_embeddings)\n",
        "\n",
        "# 使用布尔索引去除指定下标\n",
        "# arr = np.arange(len(numpy_embeddings))\n",
        "# temp = [arr % group == 7]\n",
        "# indices_to_keep = np.logical_not(np.logical_or.reduce(temp))\n",
        "# numpy_embeddings = numpy_embeddings[indices_to_keep]\n",
        "# group -= len(temp)\n",
        "\n",
        "# 使用 UMAP 进行降维，选择保留前两个主成分\n",
        "umap_model = umap.UMAP(n_components=2)\n",
        "umap_embeddings = umap_model.fit_transform(numpy_embeddings)\n",
        "\n",
        "# 根据下标为每个数据点分配不同的颜色\n",
        "colors = ['magenta', 'blue', 'green', 'purple', 'orange', 'pink', 'brown',\n",
        "          'gray', 'cyan', 'red', 'teal', 'lime', 'indigo', 'maroon', 'olive']\n",
        "colors_for_points = [colors[i % group] for i in range(len(umap_embeddings))]\n",
        "\n",
        "# 可视化 UMAP 结果\n",
        "plt.scatter(umap_embeddings[:, 0],\n",
        "            umap_embeddings[:, 1], c=colors_for_points, s=8)\n",
        "\n",
        "# 使用循环标记每个点的序号\n",
        "for i, (x, y) in enumerate(zip(umap_embeddings[:, 0], umap_embeddings[:, 1])):\n",
        "    if i < group:\n",
        "        plt.annotate(str(i+1), (x, y), textcoords=\"offset points\",\n",
        "                     xytext=(0, 10), ha='center')\n",
        "\n",
        "plt.xlabel('UMAP Component 1')\n",
        "plt.ylabel('UMAP Component 2')\n",
        "plt.title('UMAP Visualization with Labels (Starting from 1)')\n",
        "# plt.savefig(\"umap_visualization.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "EFelIEcFa1_z",
        "outputId": "d16346e2-8109-4b3d-96c0-679593da0ba7"
      },
      "outputs": [],
      "source": [
        "# T-sne\n",
        "numpy_embeddings = np.empty((0, embeddings[0].shape[1]))\n",
        "for emb in embeddings:\n",
        "    numpy_embeddings = np.vstack(\n",
        "        (numpy_embeddings, emb.cpu().detach().numpy()))\n",
        "\n",
        "# 每组图片的数量\n",
        "group = len(temp_embeddings)\n",
        "\n",
        "# 使用布尔索引去除指定下标\n",
        "# arr = np.arange(len(numpy_embeddings))\n",
        "# temp = [arr % group == 7]\n",
        "# indices_to_keep = np.logical_not(np.logical_or.reduce(temp))\n",
        "# numpy_embeddings = numpy_embeddings[indices_to_keep]\n",
        "# group -= len(temp)\n",
        "\n",
        "# 创建一个 t-SNE 对象，perplexity 参数是 t-SNE 的一个重要参数，调整它以得到更好的可视化效果\n",
        "tsne = TSNE(n_components=2, perplexity=20, learning_rate=200)\n",
        "\n",
        "# 使用 t-SNE 对数据进行降维，得到的 transformed_data 将是一个 (n_samples, 2) 的数组，其中 n_samples 是样本数量\n",
        "transformed_data = tsne.fit_transform(numpy_embeddings)\n",
        "\n",
        "# 根据下标为每个数据点分配不同的颜色\n",
        "colors = ['magenta', 'blue', 'green', 'purple', 'orange', 'pink', 'brown',\n",
        "          'gray', 'cyan', 'red', 'teal', 'lime', 'indigo', 'maroon', 'olive']\n",
        "colors_for_points = [colors[i % group] for i in range(len(transformed_data))]\n",
        "\n",
        "# 使用 matplotlib 进行绘图\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(transformed_data[:, 0],\n",
        "            transformed_data[:, 1], c=colors_for_points, s=8)\n",
        "for i in range(transformed_data.shape[0]):\n",
        "    if i < group:\n",
        "        plt.text(transformed_data[i, 0],\n",
        "                 transformed_data[i, 1], str(i + 1), fontsize=12)\n",
        "\n",
        "plt.xlabel(\"t-SNE Dimension 1\")\n",
        "plt.ylabel(\"t-SNE Dimension 2\")\n",
        "plt.title(\"t-SNE Visualization of (512,) Dimensional Vectors\")\n",
        "# plt.savefig(\"tsne_visualization.png\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jf3Cy65j8WWS",
        "VHjE1Qf9L4n7",
        "ulLdIOm9LyoK",
        "PRg5TEA7Mfet",
        "iYdnIJwIrt7n"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.13 ('llava')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "95ee6606f0e6020fb5f78b9bbb1752f4992ceac6ca53c44e595d9f09852b9381"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
